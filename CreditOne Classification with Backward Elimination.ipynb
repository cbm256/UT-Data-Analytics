{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Import data set\n",
    "dataset = pd.read_csv('default of credit card clients.csv', header=1)\n",
    "del rawData ['ID']\n",
    "rawData.rename(columns = {'default payment next month':'default'}, inplace=True)\n",
    "dataset\n",
    "#X = dataset.iloc[:, :-1].values\n",
    "#y = dataset.iloc[:, 3].values\n",
    "\n",
    "\n",
    "# Encoding categorical data i.e. change yes/no and France/Spain/Germany\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray().astype(int)\n",
    "                      \n",
    "# Change Purchased labels\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\"\"\"\n",
    "\n",
    "\"\"\"# Splitting data set into Training and Testing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 0)\"\"\"\n",
    "\n",
    "\"\"\"# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)  #transform only\n",
    "\n",
    "# Fitting the regression model to the data set\n",
    "# Create regressor here\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data \n",
    "dataset = pd.read_csv('default of credit card clients.csv', header=1)\n",
    "del dataset ['ID']\n",
    "dataset.rename(columns = {'default payment next month':'default'}, inplace=True)\n",
    "dataset[0:10]\n",
    "dataset.shape\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 23].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2682</td>\n",
       "      <td>1725</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29239</td>\n",
       "      <td>14027</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  \\\n",
       "0     -2       3913       3102        689          0          0          0   \n",
       "1      2       2682       1725       2682       3272       3455       3261   \n",
       "2      0      29239      14027      13559      14331      14948      15549   \n",
       "\n",
       "   PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0         0       689         0         0         0         0  \n",
       "1         0      1000      1000      1000         0      2000  \n",
       "2      1518      1500      1000      1000      1000      5000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[0:3,10:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20000,      2,      2,      1,     24,      2,      2,     -1,\n",
       "            -1,     -2,     -2,   3913,   3102,    689,      0,      0,\n",
       "             0,      0,    689,      0,      0,      0,      0],\n",
       "       [120000,      2,      2,      2,     26,     -1,      2,      0,\n",
       "             0,      0,      2,   2682,   1725,   2682,   3272,   3455,\n",
       "          3261,      0,   1000,   1000,   1000,      0,   2000],\n",
       "       [ 90000,      2,      2,      2,     34,      0,      0,      0,\n",
       "             0,      0,      0,  29239,  14027,  13559,  14331,  14948,\n",
       "         15549,   1518,   1500,   1000,   1000,   1000,   5000]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data set into Training and Testing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[300000,      2,      1, ...,  78794,   2900,   3000],\n",
       "       [ 50000,      1,      2, ...,    105,   2300,   1600],\n",
       "       [ 20000,      1,      3, ...,      0,      0,      0],\n",
       "       ...,\n",
       "       [130000,      2,      3, ...,   4100,      0,   5000],\n",
       "       [ 50000,      2,      3, ...,   1000,   1000,    500],\n",
       "       [140000,      2,      1, ...,   2000,   2200,   2000]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training Set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test).astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    1, 50000,     2,     2,     1,    37,     0,     0,     0,\n",
       "            0,     0,     0, 46990, 48233, 49291, 28314, 28959, 29547,\n",
       "         2000,  2019,  1200,  1100,  1069,  1000], dtype=int64), 24)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backward Elimination Preparation\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((30000,1)).astype(int), values = X, axis = 1)\n",
    "X[3,], len(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.124</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.123</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   184.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 Oct 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:40:56</td>     <th>  Log-Likelihood:    </th> <td> -14202.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 30000</td>      <th>  AIC:               </th> <td>2.845e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 29976</td>      <th>  BIC:               </th> <td>2.865e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3142</td> <td>    0.018</td> <td>   17.541</td> <td> 0.000</td> <td>    0.279</td> <td>    0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-9.053e-08</td> <td> 2.16e-08</td> <td>   -4.193</td> <td> 0.000</td> <td>-1.33e-07</td> <td>-4.82e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0145</td> <td>    0.005</td> <td>   -3.130</td> <td> 0.002</td> <td>   -0.024</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0151</td> <td>    0.003</td> <td>   -5.022</td> <td> 0.000</td> <td>   -0.021</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0238</td> <td>    0.005</td> <td>   -4.996</td> <td> 0.000</td> <td>   -0.033</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0014</td> <td>    0.000</td> <td>    5.128</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0957</td> <td>    0.003</td> <td>   34.596</td> <td> 0.000</td> <td>    0.090</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0195</td> <td>    0.003</td> <td>    5.828</td> <td> 0.000</td> <td>    0.013</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0117</td> <td>    0.004</td> <td>    3.256</td> <td> 0.001</td> <td>    0.005</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0034</td> <td>    0.004</td> <td>    0.846</td> <td> 0.398</td> <td>   -0.004</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0057</td> <td>    0.004</td> <td>    1.324</td> <td> 0.185</td> <td>   -0.003</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0008</td> <td>    0.004</td> <td>    0.225</td> <td> 0.822</td> <td>   -0.006</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>-6.225e-07</td> <td> 1.14e-07</td> <td>   -5.453</td> <td> 0.000</td> <td>-8.46e-07</td> <td>-3.99e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 1.587e-07</td> <td>  1.6e-07</td> <td>    0.990</td> <td> 0.322</td> <td>-1.56e-07</td> <td> 4.73e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> 3.005e-08</td> <td> 1.51e-07</td> <td>    0.199</td> <td> 0.842</td> <td>-2.66e-07</td> <td> 3.26e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>-6.793e-08</td> <td> 1.57e-07</td> <td>   -0.432</td> <td> 0.666</td> <td>-3.76e-07</td> <td>  2.4e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>-2.049e-08</td> <td> 1.85e-07</td> <td>   -0.111</td> <td> 0.912</td> <td>-3.82e-07</td> <td> 3.41e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> 1.153e-07</td> <td> 1.46e-07</td> <td>    0.789</td> <td> 0.430</td> <td>-1.71e-07</td> <td> 4.02e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>-7.437e-07</td> <td> 1.77e-07</td> <td>   -4.201</td> <td> 0.000</td> <td>-1.09e-06</td> <td>-3.97e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>-2.092e-07</td> <td> 1.46e-07</td> <td>   -1.436</td> <td> 0.151</td> <td>-4.95e-07</td> <td> 7.63e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>-2.874e-08</td> <td> 1.69e-07</td> <td>   -0.170</td> <td> 0.865</td> <td> -3.6e-07</td> <td> 3.02e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>-2.521e-07</td> <td> 1.84e-07</td> <td>   -1.371</td> <td> 0.170</td> <td>-6.13e-07</td> <td> 1.08e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> -3.41e-07</td> <td> 1.91e-07</td> <td>   -1.787</td> <td> 0.074</td> <td>-7.15e-07</td> <td>  3.3e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td> -9.77e-08</td> <td> 1.37e-07</td> <td>   -0.716</td> <td> 0.474</td> <td>-3.65e-07</td> <td>  1.7e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4682.286</td> <th>  Durbin-Watson:     </th> <td>   2.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>7285.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.204</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.178</td>  <th>  Cond. No.          </th> <td>2.10e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.1e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.124\n",
       "Model:                            OLS   Adj. R-squared:                  0.123\n",
       "Method:                 Least Squares   F-statistic:                     184.5\n",
       "Date:                Thu, 25 Oct 2018   Prob (F-statistic):               0.00\n",
       "Time:                        22:40:56   Log-Likelihood:                -14202.\n",
       "No. Observations:               30000   AIC:                         2.845e+04\n",
       "Df Residuals:                   29976   BIC:                         2.865e+04\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.3142      0.018     17.541      0.000       0.279       0.349\n",
       "x1         -9.053e-08   2.16e-08     -4.193      0.000   -1.33e-07   -4.82e-08\n",
       "x2            -0.0145      0.005     -3.130      0.002      -0.024      -0.005\n",
       "x3            -0.0151      0.003     -5.022      0.000      -0.021      -0.009\n",
       "x4            -0.0238      0.005     -4.996      0.000      -0.033      -0.014\n",
       "x5             0.0014      0.000      5.128      0.000       0.001       0.002\n",
       "x6             0.0957      0.003     34.596      0.000       0.090       0.101\n",
       "x7             0.0195      0.003      5.828      0.000       0.013       0.026\n",
       "x8             0.0117      0.004      3.256      0.001       0.005       0.019\n",
       "x9             0.0034      0.004      0.846      0.398      -0.004       0.011\n",
       "x10            0.0057      0.004      1.324      0.185      -0.003       0.014\n",
       "x11            0.0008      0.004      0.225      0.822      -0.006       0.008\n",
       "x12        -6.225e-07   1.14e-07     -5.453      0.000   -8.46e-07   -3.99e-07\n",
       "x13         1.587e-07    1.6e-07      0.990      0.322   -1.56e-07    4.73e-07\n",
       "x14         3.005e-08   1.51e-07      0.199      0.842   -2.66e-07    3.26e-07\n",
       "x15        -6.793e-08   1.57e-07     -0.432      0.666   -3.76e-07     2.4e-07\n",
       "x16        -2.049e-08   1.85e-07     -0.111      0.912   -3.82e-07    3.41e-07\n",
       "x17         1.153e-07   1.46e-07      0.789      0.430   -1.71e-07    4.02e-07\n",
       "x18        -7.437e-07   1.77e-07     -4.201      0.000   -1.09e-06   -3.97e-07\n",
       "x19        -2.092e-07   1.46e-07     -1.436      0.151   -4.95e-07    7.63e-08\n",
       "x20        -2.874e-08   1.69e-07     -0.170      0.865    -3.6e-07    3.02e-07\n",
       "x21        -2.521e-07   1.84e-07     -1.371      0.170   -6.13e-07    1.08e-07\n",
       "x22         -3.41e-07   1.91e-07     -1.787      0.074   -7.15e-07     3.3e-08\n",
       "x23         -9.77e-08   1.37e-07     -0.716      0.474   -3.65e-07     1.7e-07\n",
       "==============================================================================\n",
       "Omnibus:                     4682.286   Durbin-Watson:                   2.013\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7285.821\n",
       "Skew:                           1.204   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.178   Cond. No.                     2.10e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.1e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Backward Elimination\n",
    "# Create optimized matrix\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,23]]\n",
    "#            [c,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22,x23]\n",
    "\n",
    "# Select significance level : SL = 0.05\n",
    "# Fit model with all possible predictors - use new regressor\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, array([    1, 50000,     2,     2,     1,    37,     0,     0,     0,\n",
       "            0,     0,     0, 46990, 48233, 49291, 28314, 28959, 29547,\n",
       "         2000,  2019,  1200,  1100,  1069], dtype=int64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt.shape[1], X_opt[3, 0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove X16 or col 16\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23]]\n",
    "#            [c,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22]\n",
    "\n",
    "# Fit model without X2 predictors\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt.shape[1], X_opt[3, 0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.123</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.123</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   421.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 Oct 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:49:46</td>     <th>  Log-Likelihood:    </th> <td> -14216.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 30000</td>      <th>  AIC:               </th> <td>2.845e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 29989</td>      <th>  BIC:               </th> <td>2.854e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3133</td> <td>    0.018</td> <td>   17.495</td> <td> 0.000</td> <td>    0.278</td> <td>    0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1.105e-07</td> <td> 2.08e-08</td> <td>   -5.309</td> <td> 0.000</td> <td>-1.51e-07</td> <td>-6.97e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0143</td> <td>    0.005</td> <td>   -3.080</td> <td> 0.002</td> <td>   -0.023</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0153</td> <td>    0.003</td> <td>   -5.075</td> <td> 0.000</td> <td>   -0.021</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0240</td> <td>    0.005</td> <td>   -5.041</td> <td> 0.000</td> <td>   -0.033</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0014</td> <td>    0.000</td> <td>    5.138</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0974</td> <td>    0.003</td> <td>   35.537</td> <td> 0.000</td> <td>    0.092</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0201</td> <td>    0.003</td> <td>    6.071</td> <td> 0.000</td> <td>    0.014</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0178</td> <td>    0.003</td> <td>    5.983</td> <td> 0.000</td> <td>    0.012</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>-4.587e-07</td> <td> 3.45e-08</td> <td>  -13.315</td> <td> 0.000</td> <td>-5.26e-07</td> <td>-3.91e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>-7.858e-07</td> <td>  1.4e-07</td> <td>   -5.616</td> <td> 0.000</td> <td>-1.06e-06</td> <td>-5.12e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4682.501</td> <th>  Durbin-Watson:     </th> <td>   2.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>7285.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.204</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.182</td>  <th>  Cond. No.          </th> <td>1.80e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.8e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.123\n",
       "Model:                            OLS   Adj. R-squared:                  0.123\n",
       "Method:                 Least Squares   F-statistic:                     421.4\n",
       "Date:                Thu, 25 Oct 2018   Prob (F-statistic):               0.00\n",
       "Time:                        22:49:46   Log-Likelihood:                -14216.\n",
       "No. Observations:               30000   AIC:                         2.845e+04\n",
       "Df Residuals:                   29989   BIC:                         2.854e+04\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.3133      0.018     17.495      0.000       0.278       0.348\n",
       "x1         -1.105e-07   2.08e-08     -5.309      0.000   -1.51e-07   -6.97e-08\n",
       "x2            -0.0143      0.005     -3.080      0.002      -0.023      -0.005\n",
       "x3            -0.0153      0.003     -5.075      0.000      -0.021      -0.009\n",
       "x4            -0.0240      0.005     -5.041      0.000      -0.033      -0.015\n",
       "x5             0.0014      0.000      5.138      0.000       0.001       0.002\n",
       "x6             0.0974      0.003     35.537      0.000       0.092       0.103\n",
       "x7             0.0201      0.003      6.071      0.000       0.014       0.027\n",
       "x8             0.0178      0.003      5.983      0.000       0.012       0.024\n",
       "x9         -4.587e-07   3.45e-08    -13.315      0.000   -5.26e-07   -3.91e-07\n",
       "x10        -7.858e-07    1.4e-07     -5.616      0.000   -1.06e-06   -5.12e-07\n",
       "==============================================================================\n",
       "Omnibus:                     4682.501   Durbin-Watson:                   2.013\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7285.027\n",
       "Skew:                           1.204   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.182   Cond. No.                     1.80e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.8e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove X19 or col 19\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 18]]\n",
    "\n",
    "# Fit model without X2 or X1 predictors\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt.shape\n",
    "X = X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data set into Training and Testing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import estimators\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Import model metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import cross validation\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "modelKNN = KNeighborsClassifier()\n",
    "modelRF = RandomForestClassifier()\n",
    "modelGB = GradientBoostingClassifier()\n",
    "modelLOG = LogisticRegression()\n",
    "modelSVC = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74565679 0.746375   0.74221778]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.811875"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fitting - KNN\n",
    "modelKNN.fit(X_train, y_train)\n",
    "print(cross_val_score(modelKNN, X_train, y_train))\n",
    "modelKNN.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80177478 0.795125   0.80297537]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.977"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fitting - RF\n",
    "modelRF.fit(X_train, y_train)\n",
    "print(cross_val_score(modelRF, X_train, y_train))\n",
    "modelRF.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81852268 0.818125   0.81560195]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.821875"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fitting - GB\n",
    "modelGB.fit(X_train, y_train)\n",
    "print(cross_val_score(modelGB, X_train, y_train))\n",
    "modelGB.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77752781 0.7775     0.7775972 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7775416666666667"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fitting - LOG\n",
    "modelLOG.fit(X_train, y_train)\n",
    "print(cross_val_score(modelLOG, X_train, y_train))\n",
    "modelLOG.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7767779  0.776      0.77747218]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9898333333333333"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fitting - SVC\n",
    "modelSVC.fit(X_train, y_train)\n",
    "print(cross_val_score(modelSVC, X_train, y_train))\n",
    "modelSVC.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.93      0.88      4703\n",
      "          1       0.55      0.32      0.41      1297\n",
      "\n",
      "avg / total       0.77      0.80      0.78      6000\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accurancy: 0.798\n"
     ]
    }
   ],
   "source": [
    "# Make predictions - RF\n",
    "predictions = modelRF.predict(X_test)\n",
    "predAccuracy = accuracy_score(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Random Forest Metrics:')\n",
    "print('Accurancy: %.3f' % predAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88      4703\n",
      "          1       0.51      0.02      0.03      1297\n",
      "\n",
      "avg / total       0.73      0.78      0.70      6000\n",
      "\n",
      "SVR Metrics:\n",
      "Accuracy: 0.784\n"
     ]
    }
   ],
   "source": [
    "# Make predictions - SVC\n",
    "predictions = modelSVC.predict(X_test)\n",
    "predAccuracy = accuracy_score(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))\n",
    "print('SVR Metrics:')\n",
    "print('Accuracy: %.3f' % predAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90      4703\n",
      "          1       0.71      0.36      0.48      1297\n",
      "\n",
      "avg / total       0.82      0.83      0.81      6000\n",
      "\n",
      "GR Metrics:\n",
      "Accuracy: 0.830\n"
     ]
    }
   ],
   "source": [
    "# Make predictions - GB\n",
    "predictions = modelGB.predict(X_test)\n",
    "predAccuracy = accuracy_score(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))\n",
    "print('GB Metrics:')\n",
    "print('Accuracy: %.3f' % predAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88      4703\n",
      "          1       0.00      0.00      0.00      1297\n",
      "\n",
      "avg / total       0.61      0.78      0.69      6000\n",
      "\n",
      "KNN Metrics:\n",
      "Accuracy: 0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christy McCanless\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions - KNN\n",
    "predictions = modelLOG.predict(X_test)\n",
    "predAccuracy = accuracy_score(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))\n",
    "print('KNN Metrics:')\n",
    "print('Accuracy: %.3f' % predAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
